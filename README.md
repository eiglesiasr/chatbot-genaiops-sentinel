# üõ∞Ô∏è Sentinel-1 Chatbot (basado en GenAIOps)

Este proyecto es una adaptaci√≥n del repositorio original [GenAIOps_Pycon2025](https://github.com/darkanita/GenAIOps_Pycon2025), redirigido al dominio de las misiones espaciales. Implementa un chatbot tipo RAG (Retrieval-Augmented Generation) para responder preguntas relacionadas con la misi√≥n Sentinel-1, un sat√©lite equipado con un radar de apertura sint√©tica (SAR).

---

## üìö Nuevas fuentes de conocimiento

En lugar de documentos internos empresariales, este sistema se alimenta de:

- **Documento de definici√≥n del producto Sentinel-1**: Describe el sistema, especificaciones t√©cnicas y capacidades del sensor SAR. Disponible en [Sentiwiki](https://sentiwiki.copernicus.eu/__attachments/1673968/S1-RS-MDA-52-7440%20-%20Sentinel-1%20Product%20Definition%202016%20-%202.7.pdf)
- **Reporte del estado actual de la misi√≥n Sentinel-1**: Incluye informaci√≥n operativa, actualizaciones y estado de la mision para febrero de 2025. Disponible en [Sentiwiki](https://sentiwiki.copernicus.eu/__attachments/1681272/Sentinel-1-Mission_Status_Report_440.pdf?inst-v=098dc289-59b8-4d70-ad21-3a78e6b0a4b0)

> Estos documentos han sido indexados con LlamaIndex para permitir la recuperaci√≥n sem√°ntica contextual.

## üí¨ Modos de interacci√≥n: Prompts personalizados
Se han definido cinco estilos de asistente (prompt templates) para evaluar c√≥mo var√≠a el comportamiento del modelo seg√∫n el rol asignado:
| **Versi√≥n**               | **Descripci√≥n**                                                          |
| ------------------------- | -------------------------------------------------------------------- |
| `v1_asistente_cientifico` | Asistente profesional, tono cient√≠fico-formal.                       |
| `v2_resumido_directo`     | Responde de forma breve y directa, sin rodeos.                       |
| `v3_alucinogeno`          | No usa prompt, respuestas sin filtro.                                |
| `v4_asistente_experto`    | Especialista en sat√©lites y misiones espaciales, tono claro.         |
| `v5_asistente_orgulloso`  | Tambi√©n experto, pero propenso a inventar si no conoce la respuesta. |


## ‚úÖ Evaluaci√≥n autom√°tica

Se ha ampliado el sistema de evaluaci√≥n para incluir cinco criterios de calidad, implementados en `run_eval_criteria.py`:
| **Criterio**  | **Descripci√≥n**                                     |
| ------------- | ----------------------------------------------- |
| `correctness` | ¬øEs la respuesta f√°cticamente precisa?          |
| `relevance`   | ¬øEst√° relacionada directamente con la pregunta? |
| `coherence`   | ¬øEs clara y coherente?                          |
| `toxicity`    | ¬øEvita lenguaje ofensivo o problem√°tico?        |
| `harmfulness` | ¬øEvita causar da√±o o inducir a errores?         |

Las respuestas generadas por cada asistente son evaluadas autom√°ticamente por un LLM evaluador siguiendo estos criterios.

## üìä Visualizaci√≥n de resultados
Los resultados de la evaluaci√≥n pueden consultarse de dos formas:

- main_interface.py: Permite consultar la evaluaci√≥n de una respuesta espec√≠fica.

- dashboard.py: Muestra visualizaciones comparativas entre diferentes versiones de asistente.

Esto permite hacer an√°lisis A/B de calidad y comportamiento del modelo bajo distintas condiciones.

---

## üöÄ Demo

### 1. üß± Preparaci√≥n del entorno

Puedes clonar el repositorio y crear un entorno virtual con Conda:
```bash
git clone https://github.com/darkanita/GenAIOps_Pycon2025 chatbot-genaiops
cd chatbot-genaiops
conda create -n chatbot-genaiops python=3.10 -y
conda activate chatbot-genaiops
pip install -r requirements.txt
```
O bien, puedes usar CodeSpaces por medio del DevContainer de GitHub. Esto te permitir√° ejecutar el proyecto sin necesidad de instalar nada en tu m√°quina local. De cualquier modo, copia el archivo por medio de 
```bash
cp .env.example .env
```
para cargar las variables del sistema. 

> üí°
> Recuerda agregar tu API KEY. Ac√° tambi√©n puedes elegir la versi√≥n de Prompt para que el modelo use la que prefieras. Por defecto, se usa `v1_asistente_cientifico`. Adem√°s del `CHUNK_SIZE` y `CHUNK_OVERLAP` de tu preferencia

### 2. üíª Ejecuta la app principal

Primero procesa los PDFs y genera el √≠ndice vectorial por medio del siguiente comando:

```bash
python -c "from app.rag_pipeline import save_vectorstore; save_vectorstore()"
```
Despu√©s, ejecuta la app principal, donde podr√°s hacer preguntas al chatbot y ver las m√©tricas de evaluaci√≥n (tradicionales y sem√°nticas):
```bash
streamlit run app/main_interface.py
```

### 3. üß™ Evaluaci√≥n autom√°tica de calidad

Usando `tests/eval_dataset.json` como ground truth, ejecuta la evaluaci√≥n autom√°tica de calidad. Este script eval√∫a el rendimiento del modelo en funci√≥n de los criterios definidos.

```bash
python app/run_eval.py # Evaluaci√≥n tradicional de la calidad
python app/run_eval_criteria.py # Evaluaci√≥n sem√°ntica de la calidad
```

#### üìà Visualizaci√≥n de resultados

Puedes observar los resultados de la evaluaci√≥n en el dashboard. Este script genera gr√°ficos y tablas para comparar el rendimiento de diferentes versiones del asistente para las preguntas del dataset de evaluaci√≥n.

```bash
streamlit run app/dashboard.py
```

#### üõ† Validaci√≥n automatizada

Puedes evaluar el sistema de una forma alternativa y asegurarte que √©ste tenga al menos 80% de precisi√≥n con el dataset base.

```bash
pytest tests/test_run_eval.py
```
# Chatbot GenAI + Ops Sentinel  

## üìå Evidencias Experimentales  

### üîç Hallazgos Clave  

#### 1. Optimizaci√≥n de Tama√±o de Chunks  
- **Chunk size √≥ptimo**: **1024 tokens** (balance ideal entre contexto y eficiencia procesamiento).  
- **Gr√°fica de soporte**:  
  ![Comparativa Chunk Size](/evidencias/comparativa_experimentos_chunk_size.png)  

#### 2. Efectividad de Tipos de Prompt  
- **Prompts estructurados** (ej: con pasos o ejemplos) incrementan la precisi√≥n en **~22%** frente a prompts libres.  
- **Gr√°fica de soporte**:  
  ![Comparativa de Prompts](/evidencias/comparativa_tipo_prompt.png)  

#### 3. Pipeline de Experimentos  
- **Flujo validado**:  
  1. **Chunking** (1024 tokens).  
  2. **Procesamiento** con LLMs (GPT-3.5/Mistral).  
  3. **Post-procesamiento** y evaluaci√≥n.  
- **Diagrama**:  
  ![Pipeline Experimental](/evidencias/mlflow_experiments.png)  

#### 4. Res√∫menes Autom√°ticos  
- **Chunks de 1024 tokens** permiten generar res√∫menes coherentes en respuestas largas.  
- **Ejemplo visual**:  
  ![Res√∫menes](/evidencias/v2_resumido_criterio_1024.png)  

---

## üõ†Ô∏è Configuraci√≥n T√©cnica  
```bash
git clone https://github.com/eiglesiasr/chatbot-genaiops-sentinel.git  
pip install -r requirements.txt  
