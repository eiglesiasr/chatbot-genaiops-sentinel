# ğŸ›°ï¸ Sentinel-1 Chatbot (basado en GenAIOps)

Este proyecto es una adaptaciÃ³n del repositorio original [GenAIOps_Pycon2025](https://github.com/darkanita/GenAIOps_Pycon2025), redirigido al dominio de las misiones espaciales. Implementa un chatbot tipo RAG (Retrieval-Augmented Generation) para responder preguntas relacionadas con la misiÃ³n Sentinel-1, un satÃ©lite equipado con un radar de apertura sintÃ©tica (SAR).

---

## ğŸ“š Nuevas fuentes de conocimiento

En lugar de documentos internos empresariales, este sistema se alimenta de:

- **Documento de definiciÃ³n del producto Sentinel-1**: Describe el sistema, especificaciones tÃ©cnicas y capacidades del sensor SAR. Disponible en [Sentiwiki](https://sentiwiki.copernicus.eu/__attachments/1673968/S1-RS-MDA-52-7440%20-%20Sentinel-1%20Product%20Definition%202016%20-%202.7.pdf)
- **Reporte del estado actual de la misiÃ³n Sentinel-1**: Incluye informaciÃ³n operativa, actualizaciones y estado de la mision para febrero de 2025. Disponible en [Sentiwiki](https://sentiwiki.copernicus.eu/__attachments/1681272/Sentinel-1-Mission_Status_Report_440.pdf?inst-v=098dc289-59b8-4d70-ad21-3a78e6b0a4b0)

> Estos documentos han sido indexados con LlamaIndex para permitir la recuperaciÃ³n semÃ¡ntica contextual.

## ğŸ’¬ Modos de interacciÃ³n: Prompts personalizados
Se han definido cinco estilos de asistente (prompt templates) para evaluar cÃ³mo varÃ­a el comportamiento del modelo segÃºn el rol asignado:
| **VersiÃ³n**               | **DescripciÃ³n**                                                          |
| ------------------------- | -------------------------------------------------------------------- |
| `v1_asistente_cientifico` | Asistente profesional, tono cientÃ­fico-formal.                       |
| `v2_resumido_directo`     | Responde de forma breve y directa, sin rodeos.                       |
| `v3_alucinogeno`          | No usa prompt, respuestas sin filtro.                                |
| `v4_asistente_experto`    | Especialista en satÃ©lites y misiones espaciales, tono claro.         |
| `v5_asistente_orgulloso`  | TambiÃ©n experto, pero propenso a inventar si no conoce la respuesta. |


## âœ… EvaluaciÃ³n automÃ¡tica

Se ha ampliado el sistema de evaluaciÃ³n para incluir cinco criterios de calidad, implementados en `run_eval_criteria.py`:
| **Criterio**  | **DescripciÃ³n**                                     |
| ------------- | ----------------------------------------------- |
| `correctness` | Â¿Es la respuesta fÃ¡cticamente precisa?          |
| `relevance`   | Â¿EstÃ¡ relacionada directamente con la pregunta? |
| `coherence`   | Â¿Es clara y coherente?                          |
| `toxicity`    | Â¿Evita lenguaje ofensivo o problemÃ¡tico?        |
| `harmfulness` | Â¿Evita causar daÃ±o o inducir a errores?         |

Las respuestas generadas por cada asistente son evaluadas automÃ¡ticamente por un LLM evaluador siguiendo estos criterios.

## ğŸ“Š VisualizaciÃ³n de resultados
Los resultados de la evaluaciÃ³n pueden consultarse de dos formas:

- main_interface.py: Permite consultar la evaluaciÃ³n de una respuesta especÃ­fica.

- dashboard.py: Muestra visualizaciones comparativas entre diferentes versiones de asistente.

Esto permite hacer anÃ¡lisis A/B de calidad y comportamiento del modelo bajo distintas condiciones.

---

## ğŸš€ Demo

### 1. ğŸ§± PreparaciÃ³n del entorno

Puedes clonar el repositorio y crear un entorno virtual con Conda:
```bash
git clone https://github.com/darkanita/GenAIOps_Pycon2025 chatbot-genaiops
cd chatbot-genaiops
conda create -n chatbot-genaiops python=3.10 -y
conda activate chatbot-genaiops
pip install -r requirements.txt
```
O bien, puedes usar CodeSpaces por medio del DevContainer de GitHub. Esto te permitirÃ¡ ejecutar el proyecto sin necesidad de instalar nada en tu mÃ¡quina local. De cualquier modo, copia el archivo por medio de 
```bash
cp .env.example .env
```
para cargar las variables del sistema. 

> ğŸ’¡
> Recuerda agregar tu API KEY. AcÃ¡ tambiÃ©n puedes elegir la versiÃ³n de Prompt para que el modelo use la que prefieras. Por defecto, se usa `v1_asistente_cientifico`. AdemÃ¡s del `CHUNK_SIZE` y `CHUNK_OVERLAP` de tu preferencia

### 2. ğŸ’» Ejecuta la app principal

Primero procesa los PDFs y genera el Ã­ndice vectorial por medio del siguiente comando:

```bash
python -c "from app.rag_pipeline import save_vectorstore; save_vectorstore()"
```
DespuÃ©s, ejecuta la app principal, donde podrÃ¡s hacer preguntas al chatbot y ver las mÃ©tricas de evaluaciÃ³n (tradicionales y semÃ¡nticas):
```bash
streamlit run app/main_interface.py
```

### 3. ğŸ§ª EvaluaciÃ³n automÃ¡tica de calidad

Usando `tests/eval_dataset.json` como ground truth, ejecuta la evaluaciÃ³n automÃ¡tica de calidad. Este script evalÃºa el rendimiento del modelo en funciÃ³n de los criterios definidos.

```bash
python app/run_eval.py # EvaluaciÃ³n tradicional de la calidad
python app/run_eval_criteria.py # EvaluaciÃ³n semÃ¡ntica de la calidad
```

#### ğŸ“ˆ VisualizaciÃ³n de resultados

Puedes observar los resultados de la evaluaciÃ³n en el dashboard. Este script genera grÃ¡ficos y tablas para comparar el rendimiento de diferentes versiones del asistente para las preguntas del dataset de evaluaciÃ³n.

```bash
streamlit run app/dashboard.py
```

#### ğŸ›  ValidaciÃ³n automatizada

Puedes evaluar el sistema de una forma alternativa y asegurarte que Ã©ste tenga al menos 80% de precisiÃ³n con el dataset base.

```bash
pytest tests/test_run_eval.py
```
